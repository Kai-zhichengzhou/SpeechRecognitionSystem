{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "bc88c658-e39a-4ed0-8ccd-294df7c5429e",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "oDTX1_lI-ThR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ebb53574-fe2b-4452-8ded-09b7ee0ab28c",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import shutil\n",
    "import SignalProcess\n",
    "import librosa\n",
    "import torch\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "ae3babed-7416-4d3d-817e-4c7413414e68",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "XkBeXK5TQb6H",
    "outputId": "48100ad4-d946-4701-a31b-39b1c95ffda5"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# import pandas as pd\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "881062e1-b545-4b94-8b8c-8b366e158503",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "rykviCEn-aum",
    "outputId": "5fc61040-6db2-4a5e-d358-a104c9f9390e"
   },
   "outputs": [],
   "source": [
    "#Make the characters mapping \n",
    "#mapping each character label in intger form with the audio\n",
    "\n",
    "\n",
    "\n",
    "class TextMapping():\n",
    "\n",
    "  #create mapping via dictionary and transforming function between chars and ints\n",
    "    def __init__(self):\n",
    "\n",
    "    #initialize chars list\n",
    "        self.chars = ['\\'', ' ',\n",
    "             'a', 'b', \n",
    "             'c', 'd', \n",
    "             'e', 'f', \n",
    "             'g', 'h', \n",
    "             'i', 'j', \n",
    "             'k', 'l', \n",
    "             'm', 'n', \n",
    "             'o', 'p', \n",
    "             'q', 'r', \n",
    "             's', 't', \n",
    "             'u', 'v', \n",
    "             'w', 'x', \n",
    "             'y', 'z']\n",
    "\n",
    "        self.indexes = [i for i in range(len(self.chars))]\n",
    "        self.char_2_int = {}\n",
    "        self.int_2_char = {}\n",
    "        for idx in range(len(self.chars)):\n",
    "            self.char_2_int[self.chars[idx]] = self.indexes[idx]\n",
    "            self.int_2_char[idx] = self.chars[idx]\n",
    "        \n",
    "    def textToInt(self, text_sequence): #need to define a function to convert sequence to a sequences of integers\n",
    "\n",
    "\n",
    "        sequence_number = []\n",
    "\n",
    "        for char in text_sequence[0]:\n",
    "            char = char.lower()\n",
    "            sequence_number.append(self.char_2_int[char])\n",
    "        return sequence_number\n",
    "\n",
    "    def intToText(self, int_sequence):\n",
    "        sequence_char = []\n",
    "        for label in int_sequence:\n",
    "            sequence_char.append(self.int_2_char[label])\n",
    "\n",
    "            #build the string from list \n",
    "        text_decode = ''.join(sequence_char)\n",
    "        return text_decode\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# instance = TextMapping()\n",
    "text_transform = TextMapping()\n",
    "#print(text_mapping.textToInt([\"dsfsdfsfavv\"]))\n",
    "#print(text_mapping.intToText([3,4,27,14,2,5]))\n",
    "# print('aa')\n",
    "# text = ['Hello My First Speech Recognition System']\n",
    "# print(instance.textToInt(text))\n",
    "\n",
    "# ints = instance.textToInt(text)\n",
    "# print(instance.intToText(ints))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "e5dbfd57-0f64-4bd2-b076-b486c43c8333",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "YymPCT2rECGg"
   },
   "outputs": [],
   "source": [
    "#Select Subset voice data and its corresponding label data to a dir\n",
    "#Split from the subset to train and validation set with corresponding label data \n",
    "\n",
    "def train_valid_split(data_path, train_dest_path, valid_dest_path, train_set_ratio = 0.7):\n",
    "\n",
    "    data_dir = os.walk(data_path)\n",
    "  \n",
    "    train_index_lst = []\n",
    "    valid_index_lst = []\n",
    "    for path, dir_name, file_list in data_dir:\n",
    "    \n",
    "    #need to get total files in subset to calculate the number for train and valid\n",
    "        total_data = len(file_list)\n",
    "        num_train = round(total_data * 0.7)\n",
    "        num_valid = total_data - num_train\n",
    "        idx = 0\n",
    "\n",
    "    for voice_sample in file_list:\n",
    "\n",
    "        index_str = voice_sample.split('.')[0][-6:]\n",
    "        index = int(index_str)\n",
    "\n",
    "\n",
    "        sample_path = os.path.join(path, voice_sample)\n",
    "      #check the split boundary for train and validation dataset while copying and moving the data\n",
    "        dest_path = os.path.join(train_dest_path, voice_sample) if idx <= num_train else os.path.join(valid_dest_path, voice_sample)\n",
    "\n",
    "        train_index_lst.append(index) if idx <= num_train else valid_index_lst.append(index)\n",
    "        shutil.copy(sample_path, dest_path)\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    return index_lst\n",
    "\n",
    "\n",
    "def get_labels_from_CSV(csv_path):\n",
    "    with open(csv_path, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(reader)\n",
    "    labels = []\n",
    "    for idx in range(1, len(data)):\n",
    "        labels.append([data[idx][1]])\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "1039ddd1-ac45-419b-8b39-9be21bb74182",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "B8yME8t4VsmD",
    "outputId": "8bef27da-1143-4883-8b2a-cb0fe2a92001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "train_labels = get_labels_from_CSV('./subset_train.csv')\n",
    "#valid_labels = get_labels_from_CSV('./subset_valid.csv')\n",
    "# train_labels = get_labels_from_CSV('drive/MyDrive/ASR/subset_train.csv')\n",
    "# valid_labels = get_labels_from_CSV('drive/MyDrive/ASR/subset_valid.csv')\n",
    "train_labels = train_labels[:24]\n",
    "print(len(train_labels))\n",
    "#print(len(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c4516191-d745-4ca3-984d-33aeed854f84",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "ooWAoA9nPfJk"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from glob import glob\n",
    "#defined the dataset and how the data and label is going to be taken \n",
    "#the audio data and label should be matched\n",
    "#design how to match the data with labels from csv\n",
    "\n",
    "FRAME_SIZE = 2048\n",
    "HOP_SIZE = 512\n",
    "n_mels = 128\n",
    "\n",
    "def data_preprocessing(audio_waveform, sequence):\n",
    "    melSpec = []\n",
    "    labels = []\n",
    "    melSpec = SignalProcess.getMelspectrogram(audio_waveform, n_fft = FRAME_SIZE, hop_length = HOP_SIZE, n_mels = n_mels, fmin = 10, fmax = 8000)\n",
    "\n",
    "    melSpec = np.transpose(melSpec)\n",
    "    labels = text_transform.textToInt(sequence)\n",
    "    return torch.Tensor(melSpec), torch.Tensor(labels)\n",
    "\n",
    "\n",
    "def collate_fn(data):\n",
    "    melspecs = []\n",
    "    labels = []\n",
    "    melspecs_length = []\n",
    "    labels_length = []\n",
    "    for melspec, label, mel_len, label_len in data:\n",
    "        melspecs.append(melspec)\n",
    "        labels.append(label)\n",
    "        melspecs_length.append(melspec.shape[0]//2)\n",
    "        labels_length.append(label_len)\n",
    "        \n",
    "        \n",
    "    melspecs = nn.utils.rnn.pad_sequence(melspecs, batch_first = True)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first = True)\n",
    "#     print(\"Batch Mel:\\n\", melspecs)\n",
    "#     print(\"Batch Labels:\\n\",labels)\n",
    "    \n",
    "    #print(\"check bug\")\n",
    "    return melspecs, labels, melspecs_length, labels_length\n",
    "\n",
    "\n",
    "class TrainDataset(data.Dataset):\n",
    "    def __init__(self, labels,root = ''):\n",
    "        super(TrainDataset, self).__init__()\n",
    "        self.audio_files = sorted(glob(os.path.join(root, '*.wav')))[:3500]\n",
    "        self.waveforms = []\n",
    "        self.text_labels = labels\n",
    "        #print(self.audio_files)\n",
    "        idx = 0\n",
    "        for audio_file in self.audio_files:\n",
    "            #print(idx)\n",
    "            waveform, _ = librosa.load(audio_file)\n",
    "            #print(waveform.shape)\n",
    "            self.waveforms.append(waveform)\n",
    "            idx += 1\n",
    "#             if idx == 3500:\n",
    "#                 return \n",
    "\n",
    "        #print('waveform:',self.waveforms)\n",
    "        #print('labels:', self.text_labels)\n",
    "\n",
    "        print(\"finish\")\n",
    "\n",
    "        #apply signal processing so that get a dataset with waveform and labels correspondingly matched\n",
    "        #the transform should be converted in the init stage to cut cost while get item\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        audio_path = self.audio_files[index]\n",
    "\n",
    "        waveform = self.waveforms[index]\n",
    "\n",
    "        sequence_label = self.text_labels[index]\n",
    "\n",
    "        melSpec, labels = data_preprocessing(waveform, sequence_label)\n",
    "        #print(\"preprocessing here.\")\n",
    "        \n",
    "        mel_length = melSpec.shape[0]\n",
    "        #print('input length', mel_length)\n",
    "        \n",
    "        label_length = len(labels)\n",
    "\n",
    "\n",
    "\n",
    "        return melSpec, labels, mel_length, label_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_files)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "adf944eb-38a1-4220-9fe9-2f8681e4e7ea",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "j_RApjVXP8cr"
   },
   "outputs": [],
   "source": [
    "demo_train_labels = train_labels[:24]\n",
    "demo_path = './demoData/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ea679d6b-6f87-4bd2-9541-3c0bdde67cfb",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "a31Gsz2EQnsw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "train_demo = TrainDataset(demo_train_labels,demo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2ac81b4b-9446-4b72-a656-3c948e6ce384",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "pX_ROjVuQpaQ"
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset = train_demo, batch_size = 20, collate_fn = collate_fn,num_workers = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6bb89016-82d8-435c-8b07-7996548710ba",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    },
    "id": "Q5MVlHEiRrP4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # #visualize some demo first to see the shape of the data in each batch\n",
    "\n",
    "\n",
    "# for idx, data in enumerate(train_loader):\n",
    "    \n",
    "#     melspec, labels, mel, _ = data\n",
    "#     melspec = melspec.unsqueeze(1)\n",
    "#     print(\"Batch Mel:\\n\", melspec)\n",
    "#     print(\"Batch Mel Shape:\\n\",melspec.shape)\n",
    "#     print(\"Batch Label:\\n\", labels)\n",
    "#     print(\"Batch Label shape:\\n\", labels.shape)\n",
    "#     #melspec = melspec.squeeze(1)\n",
    "    \n",
    "#     #the data size is (batch, channel, timestep, n_mels(features))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "603a917e-29d0-46e9-afea-17d6ea2523b2",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#define model \n",
    "#data shape (batch, channel, timestep, feature)\n",
    "\n",
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ASR_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(ASR_Model, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        print(x.shape)\n",
    "        x = self.rescnn_layers(x)\n",
    "        print(x.shape)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3a994845-9333-4669-9c9a-0a8ae2e46139",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#thoughts of output shape\n",
    "#it is possible to build output of timestep versus chars\n",
    "#if model can get the probs of each char for each timestep\n",
    "#then the output may be (timestep, chars) or (chars, timestep)\n",
    "\n",
    "#output probs\n",
    "\n",
    "\n",
    "\n",
    "#define the combined model of cnn & rnn \n",
    "# class ASR_Model(nn.Module):\n",
    "    \n",
    "#     def __init__(self, num_convs, num_features, stride, num_filters, dropout, num_rnn, embedding_dim, num_class):\n",
    "#         super(ASR_Model, self).__init__()\n",
    "        \n",
    "#         num_features = num_features // 2\n",
    "#         #apply one single conv to input using 32 filters to get 32 channels with more features\n",
    "#         self.conv1 = nn.Conv2d(1, num_filters, kernel_size = 3, stride = stride, padding = 1) #shape should be (B, 32, H, W)\n",
    "        \n",
    "\n",
    "#         self.resNet_Layers = nn.Sequential(*[\n",
    "#             ResidualBlock(num_filters, num_filters, kernel = 3, stride = 1, dropout = dropout,\n",
    "#                           n_features = num_features) for idx in range(num_convs)])\n",
    "        \n",
    "#         #connect output of resnet to a fully-connected layer and do the forward compuataion\n",
    "#         #neurons in fc then fed into rnn, so keep the dim in fc same as the feature dims of rnn\n",
    "#         self.fc = nn.Linear(num_features * num_filters, embedding_dim)\n",
    "        \n",
    "#         self.GRU_Layers = nn.Sequential(*[\n",
    "#             Bidirectional_GRU(embedding_dim = embedding_dim if idx == 0 else embedding_dim * 2 ,hidden_size = embedding_dim,\n",
    "#             dropout = dropout, batch_first = True) \n",
    "#             for idx in range(num_rnn)])\n",
    "        \n",
    "#         self.linear = nn.Linear(embedding_dim * 2, embedding_dim)\n",
    "#         self.activation = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "#         self.output_class = nn.Linear(embedding_dim, num_class)\n",
    "        \n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "        \n",
    "#         #apply each layer to input -> output should be (timestep, class)\n",
    "        \n",
    "        \n",
    "#         x = self.conv1(x) #(batch, channels, timestep, feature)\n",
    "        \n",
    "#         #apply Resnet \n",
    "#         x = self.resNet_Layers(x)\n",
    "#         #connect layer after last resnet block to a fc layer\n",
    "#         #reshape output of resnet first to put channels and features together\n",
    "#         x_shapes = x.size()\n",
    "#         #print(x.shape)\n",
    "#         x = x.view(x_shapes[0],x_shapes[2],x_shapes[1] * x_shapes[3]) #(Batch,timestep, channels * dims)\n",
    "#         #print(x.shape)\n",
    "#         x = self.fc(x) \n",
    "#         #print(\"after fc\",x.shape)\n",
    "#         #fc layer -> rnn model \n",
    "#         x = self.GRU_Layers(x)\n",
    "        \n",
    "#         #get the output from rnn layer (batch, timestep, dims)\n",
    "#         x = self.linear(x)\n",
    "#         x = self.activation(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.output_class(x)\n",
    "        \n",
    "#         return x\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "261ed19b-5d7d-48d6-b122-73f5e5caa04d",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#demo_model = SpeechRecognitionModel_1(3,5,512,29,128,2,0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5691a423-2132-4469-9cb3-d269724006e0",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": [
    "# for idx, data in enumerate(train_loader):\n",
    "    \n",
    "#     print(\"batch\", idx)\n",
    "#     melspec, labels, mel_len, label_len = data\n",
    "#     melspec = melspec.unsqueeze(1)\n",
    "# #     print(\"Batch Mel:\\n\", melspec)\n",
    "# #     print(\"Batch Mel Shape:\\n\",melspec.shape)\n",
    "# #     print(\"Batch Label:\\n\", labels)\n",
    "# #     print(\"Batch Label shape:\\n\", labels.shape)\n",
    "#     #melspec = melspec.squeeze(1)\n",
    "    \n",
    "#     x = ASR_M(melspec)\n",
    "\n",
    "#     print(\"output shape:\\n\", x.shape)\n",
    "#     print(\"the output is:\\n\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5b916b55-b99b-4fb1-b0f2-4264437d3d1e",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def min_edit_distance_sentence(pred_sequence, label_sequence):\n",
    "\n",
    "    '''     ' ' a c d b c e\n",
    "        ' '  0  1 2 3 4 5 6\n",
    "        a    1  \n",
    "        b    2\n",
    "        b    3\n",
    "        c    4\n",
    "        e    5\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    if pred_sequence == label_sequence:\n",
    "        return 0\n",
    "\n",
    "    if len(pred_sequence) == 0:\n",
    "        return len(label_sequence)\n",
    "\n",
    "    if len(label_sequence) == 0:\n",
    "        return len(pred_sequence)\n",
    "\n",
    "    height = len(pred_sequence) + 1\n",
    "    width = len(label_sequence) + 1\n",
    "\n",
    "    dp = [ [ 0 for w in range(width)] for h in range(height)]\n",
    "    for i in range(height):\n",
    "        dp[i][0] = i\n",
    "    for j in range(width):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, height):\n",
    "\n",
    "        for j in range(1, width):\n",
    "            if pred_sequence[i -1] == label_sequence[j -1]:\n",
    "                dp[i][j] = dp[i -1][j -1]\n",
    "            else:\n",
    "\n",
    "                dp[i][j] = min(dp[i - 1][j - 1], dp[i][j - 1], dp[i - 1][j]) + 1\n",
    "\n",
    "    return dp[height - 1][width -1]\n",
    "\n",
    "\n",
    "word_demo = ['word', 'test','essential','important']\n",
    "word_pred = ['word', 'text', 'essentials','important','yy']\n",
    "print(min_edit_distance_sentence(word_pred,word_demo))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "7818aeb1-dc5c-4a4a-8a5a-9c549861dfa0",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def calc_word_error_rate(pred_sequence, label_sequence):\n",
    "\n",
    "    if len(label_sequence) == 0:\n",
    "        return \"Error of the length of Label Sequence. Label should not be empty.\"\n",
    "\n",
    "    #calculate the word errors between two sentence\n",
    "    pred_sequence = pred_sequence.lower()\n",
    "    label_sequence = label_sequence.lower()\n",
    "\n",
    "    #split sentence to words\n",
    "    pred_words = pred_sequence.split(' ')\n",
    "    label_sequence = label_sequence.split(' ')\n",
    "\n",
    "    edit_distance = min_edit_distance_sentence(pred_sequence, label_sequence)\n",
    "\n",
    "    WER = float(edit_distance) / len(label_sequence)\n",
    "\n",
    "    return WER\n",
    "\n",
    "\n",
    "\n",
    "def calc_char_error_rate(pred_sequence, label_sequence):\n",
    "\n",
    "    if len(label_sequence) == 0:\n",
    "        return \"Error of the length of Label Sequence. Label should not be empty.\"\n",
    "    pred_sequence = pred_sequence.lower()\n",
    "    label_sequence = label_sequence.lower()\n",
    "\n",
    "    #remove the space is necessary\n",
    "\n",
    "    pred_sequence = ''.join(pred_sequence.split(' '))\n",
    "    label_sequence = ''.join(label_sequence.split(' '))\n",
    "    distance = min_edit_distance_sentence(pred_sequence,label_sequence)\n",
    "\n",
    "    CER = float(distance) / len(label_sequence)\n",
    "\n",
    "    return CER\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3eea332b-b691-4a3b-a173-f9353095c554",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def SequenceDecoder(output_matrix,labels, label_lengths,blank_label = 28,collapse_repeated=True):\n",
    "\n",
    "    #print(output_matrix.shape)\n",
    "    arg_maxes = torch.argmax(output_matrix, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "\t    decode = []\n",
    "\t    targets.append(text_transform.intToText(labels[i][:label_lengths[i]].tolist()))\n",
    "\t    for j, index in enumerate(args):\n",
    "\t\t    if index != blank_label:\n",
    "\t\t\t    if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "\t\t\t\t    continue\n",
    "\t\t\t    decode.append(index.item())\n",
    "\t    decodes.append(text_transform.intToText(decode))\n",
    "    return decodes, targets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "afbeddda-3813-4fad-9411-dc937d25d205",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# l = [[5,6,7,10,5,24,5,19,0,1,2], [1,4,5,2,5,2,6,8],[2,4,15,4,5,1,9,3,4],[1,9,11,12,15,16,12]]\n",
    "# l_length = [11, 8, 9, 7]\n",
    "# out_demo = np.random.randn(4, 45, 28)\n",
    "# out_demo = torch.tensor(out_demo)\n",
    "# print(SequenceDecoder(l, l_length, out_demo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9a4817cc-86fe-40fd-86d7-076459e1332e",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "42b7c515-0422-4db0-b1f8-bddd303893e5",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "eacb8513-3a24-46a5-9fdf-f979e2b48423",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a1cf7968-46ba-457f-9b2a-5484895da411",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#define model \n",
    "#data shape (batch, channel, timestep, feature)\n",
    "\n",
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"shape!\")\n",
    "        #print(x.shape)\n",
    "       \n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        #print(\"run to here\")\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ASR_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(ASR_Model, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        #print(x.shape)\n",
    "        x = self.rescnn_layers(x)\n",
    "\n",
    "        #print(x.shape)\n",
    "        sizes = x.size()\n",
    "\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "6a79d010-2b61-4245-86f1-c42931c7ab5d",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "EPOCH: 0 | Batch: 0  | loss: 4.206844329833984\n",
      "EPOCH: 0 | Batch: 1  | loss: 6.713436126708984\n",
      "EPOCH: 0 | Batch: 2  | loss: 5.873776435852051\n",
      "EPOCH: 0 | Batch: 3  | loss: 25.340164184570312\n",
      "EPOCH: 0 | Batch: 4  | loss: 11.491445541381836\n",
      "EPOCH: 0 | Batch: 5  | loss: 8.137561798095703\n",
      "EPOCH: 0 | Avg Loss : 10.293871402740479\n",
      "EPOCH: 1 | Batch: 0  | loss: 6.289431095123291\n",
      "EPOCH: 1 | Batch: 1  | loss: 6.695800304412842\n",
      "EPOCH: 1 | Batch: 2  | loss: 7.696942329406738\n",
      "EPOCH: 1 | Batch: 3  | loss: 5.476521015167236\n",
      "EPOCH: 1 | Batch: 4  | loss: 5.1672587394714355\n",
      "EPOCH: 1 | Batch: 5  | loss: 4.486143589019775\n",
      "EPOCH: 1 | Avg Loss : 5.968682845433553\n",
      "EPOCH: 2 | Batch: 0  | loss: 4.0624189376831055\n",
      "EPOCH: 2 | Batch: 1  | loss: 3.939307689666748\n",
      "EPOCH: 2 | Batch: 2  | loss: 3.312819480895996\n",
      "EPOCH: 2 | Batch: 3  | loss: 3.419518232345581\n",
      "EPOCH: 2 | Batch: 4  | loss: 3.488250255584717\n",
      "EPOCH: 2 | Batch: 5  | loss: 3.8106727600097656\n",
      "EPOCH: 2 | Avg Loss : 3.672164559364319\n",
      "EPOCH: 3 | Batch: 0  | loss: 3.7999155521392822\n",
      "EPOCH: 3 | Batch: 1  | loss: 3.574477434158325\n",
      "EPOCH: 3 | Batch: 2  | loss: 3.202558755874634\n",
      "EPOCH: 3 | Batch: 3  | loss: 3.5539445877075195\n",
      "EPOCH: 3 | Batch: 4  | loss: 3.3444714546203613\n",
      "EPOCH: 3 | Batch: 5  | loss: 3.6683740615844727\n",
      "EPOCH: 3 | Avg Loss : 3.5239569743474326\n",
      "EPOCH: 4 | Batch: 0  | loss: 3.824028968811035\n",
      "EPOCH: 4 | Batch: 1  | loss: 3.547187328338623\n",
      "EPOCH: 4 | Batch: 2  | loss: 3.1623411178588867\n",
      "EPOCH: 4 | Batch: 3  | loss: 3.633350133895874\n",
      "EPOCH: 4 | Batch: 4  | loss: 3.3436279296875\n",
      "EPOCH: 4 | Batch: 5  | loss: 3.8675315380096436\n",
      "EPOCH: 4 | Avg Loss : 3.5630111694335938\n",
      "EPOCH: 5 | Batch: 0  | loss: 3.69297456741333\n",
      "EPOCH: 5 | Batch: 1  | loss: 3.5322515964508057\n",
      "EPOCH: 5 | Batch: 2  | loss: 3.3374037742614746\n",
      "EPOCH: 5 | Batch: 3  | loss: 3.3281517028808594\n",
      "EPOCH: 5 | Batch: 4  | loss: 3.2998650074005127\n",
      "EPOCH: 5 | Batch: 5  | loss: 4.062775135040283\n",
      "EPOCH: 5 | Avg Loss : 3.5422369639078775\n",
      "EPOCH: 6 | Batch: 0  | loss: 3.438203811645508\n",
      "EPOCH: 6 | Batch: 1  | loss: 3.452399730682373\n",
      "EPOCH: 6 | Batch: 2  | loss: 3.2862372398376465\n",
      "EPOCH: 6 | Batch: 3  | loss: 3.275865077972412\n",
      "EPOCH: 6 | Batch: 4  | loss: 3.344330310821533\n",
      "EPOCH: 6 | Batch: 5  | loss: 3.868257522583008\n",
      "EPOCH: 6 | Avg Loss : 3.4442156155904136\n",
      "EPOCH: 7 | Batch: 0  | loss: 3.4422850608825684\n",
      "EPOCH: 7 | Batch: 1  | loss: 3.4110107421875\n",
      "EPOCH: 7 | Batch: 2  | loss: 3.1430230140686035\n",
      "EPOCH: 7 | Batch: 3  | loss: 3.3405256271362305\n",
      "EPOCH: 7 | Batch: 4  | loss: 3.2345926761627197\n",
      "EPOCH: 7 | Batch: 5  | loss: 3.7279744148254395\n",
      "EPOCH: 7 | Avg Loss : 3.3832352558771768\n",
      "EPOCH: 8 | Batch: 0  | loss: 3.4530820846557617\n",
      "EPOCH: 8 | Batch: 1  | loss: 3.4328556060791016\n",
      "EPOCH: 8 | Batch: 2  | loss: 3.165123224258423\n",
      "EPOCH: 8 | Batch: 3  | loss: 3.332695722579956\n",
      "EPOCH: 8 | Batch: 4  | loss: 3.225839138031006\n",
      "EPOCH: 8 | Batch: 5  | loss: 3.777193069458008\n",
      "EPOCH: 8 | Avg Loss : 3.3977981408437095\n",
      "EPOCH: 9 | Batch: 0  | loss: 3.434171199798584\n",
      "EPOCH: 9 | Batch: 1  | loss: 3.44441556930542\n",
      "EPOCH: 9 | Batch: 2  | loss: 3.138920307159424\n",
      "EPOCH: 9 | Batch: 3  | loss: 3.3435921669006348\n",
      "EPOCH: 9 | Batch: 4  | loss: 3.1678409576416016\n",
      "EPOCH: 9 | Batch: 5  | loss: 3.8406543731689453\n",
      "EPOCH: 9 | Avg Loss : 3.394932428995768\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#define training process\n",
    "#train data in train_loader\n",
    "\n",
    "def train(model, epochs, device, train_data, loss_func, optimizer):\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        loss_total = 0\n",
    "        \n",
    "        # print(\"Current EPOCH:\", epoch)\n",
    "        # batch_cer = []\n",
    "        # batch_wer = []\n",
    "    \n",
    "        for idx, data in enumerate(train_data):\n",
    "            \n",
    "\n",
    "            melspec, labels, melspectrogram_length, labels_length = data\n",
    "            melspec = melspec.unsqueeze(1)\n",
    "            # melspec, labels = melspec.to(torch.float16), labels.to(torch.float16)\n",
    "            melspec, labels = melspec.to(device), labels.to(device)\n",
    "            #batch_size = melspec.shape[0]\n",
    "            #print(melspec.shape)\n",
    "            #print(\"label lengths:\", labels_length)\n",
    "            #print(\"mel lengths :\", melspectrogram_length)\n",
    "            optimizer.zero_grad() #initialize gradients\n",
    "            #print(melspec.shape)\n",
    "            melspec = melspec.transpose(2,3)\n",
    "            output_probs_mat = ASR_M(melspec)\n",
    "            output_probs_mat = F.log_softmax(output_probs_mat, dim = 2)\n",
    "            #print(\"output shape\",output_probs_mat.shape)\n",
    "            #print(labels.shape)\n",
    "            #print(output_probs_mat)\n",
    "            \n",
    "            output_probs_mat = output_probs_mat.transpose(0,1)\n",
    "            #print(output_probs_mat)\n",
    "            seq_len = output_probs_mat.shape[0]\n",
    "            #use output prob matrix to calculate CTC LOSS\n",
    "            #mel_length = torch.full(size = (batch_size,), fill_value = seq_len)\n",
    "            #melspectrogram_length = melspectrogram_length / 2\n",
    "            #mel_length = torch.tensor(melspectrogram_length, dtype = torch.float16)\n",
    "            mel_length = torch.tensor(melspectrogram_length)\n",
    "            labels_tensor = torch.tensor(labels_length)\n",
    "            #print(mel_length.dtype)\n",
    "            #abels_tensor = torch.tensor(labels_length, dtype = torch.float16)\n",
    "            #print(mel_length)\n",
    "            #print(labels_tensor)\n",
    "            #print(labels_tensor)\n",
    "            loss = loss_func(output_probs_mat, labels, mel_length,labels_tensor)\n",
    "            loss_total += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            del melspec, labels, mel_length,labels_tensor, output_probs_mat\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            #pred_decode, label_text = SequenceDecoder(output_probs_mat.transpose(0,1), labels,labels_length)\n",
    "            #print(\"pred : \", pred_decode)\n",
    "            #print(\"label_text :\", label_text)\n",
    "            #for i in range(len(pred_decode)):\n",
    "                #batch_cer.append(calc_char_error_rate(pred_decode[i], label_text[i]))\n",
    "                #batch_wer.append(calc_word_error_rate(pred_decode[i], label_text[i]))\n",
    "\n",
    "\n",
    "            print(f'EPOCH: {epoch} | Batch: {idx}  | loss: {loss.item()}')\n",
    "            \n",
    "\n",
    "            #torch.cuda.empty_cache()\n",
    "\n",
    "            \n",
    "            #scheduler.step()\n",
    "\n",
    "        # avg_wer_per_epoch = sum(batch_wer)/len(batch_wer)\n",
    "        # avg_cer_per_epoch = sum(batch_cer)/len(batch_cer)\n",
    "        # WER.append(avg_wer_per_epoch)\n",
    "        # CER.append(avg_cer_per_epoch)\n",
    "        avg_loss = loss_total / len(train_data)\n",
    "        train_loss.append(avg_loss)\n",
    "        loss_total = 0\n",
    "        print(f'EPOCH: {epoch} | Avg Loss : {avg_loss}')\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "train_loss = [] #loss per epoch\n",
    "WER = []\n",
    "CER = []\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "ASR_M = ASR_Model(3, 5, 512, 29, 128,2,0.1)\n",
    "ASR_M.cuda()\n",
    "train_loader = DataLoader(dataset = train_demo, batch_size = 4, collate_fn = collate_fn, num_workers = 8)\n",
    "loss_fn = nn.CTCLoss(blank = 28).cuda() #use CTC Loss\n",
    "optimizer = torch.optim.AdamW(ASR_M.parameters(), lr = 0.01, weight_decay = 0.01) \n",
    "cnt = 0    \n",
    "train(ASR_M, 10, device, train_loader, loss_fn, optimizer)\n",
    "print(cnt)\n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 86,
     "id": "8373eb21-d04d-4fdd-86a7-a536a92ab472",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 95,
     "id": "a9920364-fbb4-4173-a9fb-04b813e43c76",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 25 12:04:09 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 5000     Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| 33%   36C    P8    10W / 230W |   2550MiB / 16125MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "16ac035d-7043-4ca9-8188-a1bf0a305169",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(ASR_M, 'model_demo.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "0c2a7b3c-9924-4088-bdfe-2635b5434d42",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([12, 19, 26, 15, 29, 12, 24, 24, 15, 28, 25, 25, 25, 22, 17, 17])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cnt)\n",
    "target_lengths = torch.randint(10,30,(16,), dtype=torch.long)\n",
    "target_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "97800b9e-6052-415c-aba9-569d6d50be83",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a4d16d06-1550-4b84-bba5-b4e10e482993",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": [
    "# import  matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot([i for i in range(20)], train_loss,'r--')\n",
    "\n",
    "# plt.savefig('loss.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "23e82dac-d958-46f8-b78b-a2f6c24f59e7",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.8104810414995467, 3.052863738196237, 3.0228508744921, 2.9966610608782087, 2.981540322984968, 2.9723246615273613, 2.957734627042498, 2.954313404900687, 2.9896311242239815, 2.975481491088867, 2.9388402557373046, 3.1165716470990863, 2.990710413796561, 2.9225049005235944, 2.896951701300485, 2.8865172617776054, 2.883577781404768, 2.8880960164751324, 2.8903752517700196, 2.8883916105542866]\n"
     ]
    }
   ],
   "source": [
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "385d854a-e4c6-4915-b9d5-ec996a6260a0",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot([i for i in range(20)], WER, 'g--')\n",
    "plt.plot([i for i in range(20)],CER, 'y--')\n",
    "plt.savefig('WER_CER.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "204e87ca-829d-4ed7-ba0a-5a9f476a6bf7",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5c26c697-9d05-4bbb-a62b-e0df6a7b9924",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f64c12cf-9e10-4e06-ae32-93c7b057d706",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4ffe065f-e458-4689-9baf-53f873d0b891",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f7b752c1-b333-4f0a-8ec0-cd9ac5e58f2b",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3cf86c29-2cdd-4dcc-a23f-b292b8fb9356",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "3fd77d15-353c-42b8-861f-4834c2880af0",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a70e91b9-0eeb-44a4-9057-34c5eb156a09",
     "kernelId": "9f3e86f2-1ba2-4629-bd06-eb31fdc35f44"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ASR_Model.ipynb",
   "provenance": []
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
